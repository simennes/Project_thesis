stat_function(fun = dnorm, args = list(mean = true_mu1, sd = sqrt(true_sigma2)), color = "green", size = 1) +
labs(title = "Histogram of Y with True Distribution",
x = "Y Values",
y = "Density") +
theme_minimal()
# Combine the two histograms
combined_hist_plot <- plot_x_hist + plot_y_hist +
plot_layout(ncol = 2)
print(combined_hist_plot)
# Plot actual sampled x and y as histogram, true distributions as line
# x-axis: value
# y-axis: density
# Create a data frame for plotting
x_df <- data.frame(x = sim_data$x)
y_df <- data.frame(y = sim_data$y)
# Create the histogram for x
plot_x_hist <- ggplot(x_df, aes(x = x)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "lightblue", color = "black", alpha = 0.7) +
stat_function(fun = dnorm, args = list(mean = true_mu0, sd = sqrt(true_sigma2)), color = "black", size = 0.8) +
labs(title = "Histogram of X",
x = "X Values",
y = "Density") +
theme_minimal()
# Create the histogram for y
plot_y_hist <- ggplot(y_df, aes(x = y)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
stat_function(fun = dnorm, args = list(mean = true_mu1, sd = sqrt(true_sigma2)), color = "black", size = 0.8) +
labs(title = "Histogram of Y",
x = "Y Values",
y = "Density") +
theme_minimal()
# Combine the two histograms
combined_hist_plot <- plot_x_hist + plot_y_hist +
plot_layout(ncol = 2)
print(combined_hist_plot)
# Plot actual sampled x and y as histogram, true distributions as line
# x-axis: value
# y-axis: density
# Create a data frame for plotting
x_df <- data.frame(x = sim_data$x)
y_df <- data.frame(y = sim_data$y)
# Create the histogram for x
plot_x_hist <- ggplot(x_df, aes(x = x)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "lightblue", color = "black", alpha = 0.7) +
stat_function(fun = dnorm, args = list(mean = true_mu0, sd = sqrt(true_sigma2)), color = "black", size = 0.7) +
labs(title = "Histogram of X",
x = "X Values",
y = "Density") +
theme_minimal()
# Create the histogram for y
plot_y_hist <- ggplot(y_df, aes(x = y)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
stat_function(fun = dnorm, args = list(mean = true_mu1, sd = sqrt(true_sigma2)), color = "black", size = 0.7) +
labs(title = "Histogram of Y",
x = "Y Values",
y = "Density") +
theme_minimal()
# Combine the two histograms
combined_hist_plot <- plot_x_hist + plot_y_hist +
plot_layout(ncol = 2)
print(combined_hist_plot)
# Save the combined histogram plot
ggsave("combined_hist_plot.png", plot = combined_hist_plot, width = 12, height = 6)
knitr::opts_chunk$set(echo = TRUE)
library(coda)
library(microbenchmark)
library(latex2exp)
library(mvtnorm)
library(ggplot2)
library(tidyr)
library(dplyr)
library(patchwork)
simulate_z_u <- function(n, mu_0, mu_1, sigma2) {
x <- rnorm(n, mu_0, sqrt(sigma2))
y <- rnorm(n, mu_1, sqrt(sigma2))
z <- pmax(x, y)
u <- as.numeric(x < y)
return(list(z = z, u = u, x= x, y = y))
}
# Returns a list with mean and variance
trunc_norm_moments <- function(mu, sigma2, b) {
# Define parameters for mean and variance
beta <- (b - mu) / sqrt(sigma2)
p_beta <- pnorm(beta)
phi_beta <- dnorm(beta)
ratio <- phi_beta / p_beta
# Calculate mean and variance
cond_mean <- mu - sqrt(sigma2) * ratio
cond_var <- sigma2 * (1 - beta * ratio - ratio^2)
return(list(mean = cond_mean, var = cond_var))
}
# EM Algorithm
em_algorithm <- function(z, u, mu0_init, mu1_init, sigma2_init,
tol = 1e-7, max_iter = 1000) {
# Initialization
mu0 <- mu0_init
mu1 <- mu1_init
sigma2 <- sigma2_init
n <- length(z)
param_hist <- matrix(NA, nrow = max_iter + 1, ncol = 3)
param_hist[1,] <- c(mu0, mu1, sigma2)
if (sigma2 <= 0) stop("Initial sigma^2 must be positive.")
for (iter in 1:max_iter) {
# --- E-step ---
# Calculate m_i^(t) and v_i^(t) for each observation i
m_t <- numeric(n)
v_t <- numeric(n)
for (i in 1:n) {
if (u[i] == 1) { # x_i trunc norm, y_i = z_i
moments <- trunc_norm_moments(mu = mu0, sigma2 = sigma2, b = z[i])
} else { # y_i trunc norm, x_i = z_i
moments <- trunc_norm_moments(mu = mu1, sigma2 = sigma2, b = z[i])
}
m_t[i] <- moments$mean
v_t[i] <- moments$var
}
# --- M-step ---
# Update means
mu0_new <- mean((1-u)*z + u*m_t)
mu1_new <- mean((1-u)*m_t + u*z)
# Update variance
term1_var <- (1-u) * ( (z - mu0_new)^2 + (m_t - mu1_new)^2 )
term2_var <- u * ( (z - mu1_new)^2 + (m_t - mu0_new)^2 )
sum_for_sigma2 <- sum(v_t + term1_var + term2_var)
sigma2_new <- sum_for_sigma2 / (2 * n)
# --- Check convergence ---
param_old <- c(mu0, mu1, sigma2)
param_new <- c(mu0_new, mu1_new, sigma2_new)
param_change <- sqrt(sum((param_new - param_old)^2))
param_hist[iter+1,] <- param_new
# Update parameters for next iteration
mu0 <- mu0_new
mu1 <- mu1_new
sigma2 <- sigma2_new
if (param_change < tol) {
break
}
} # End EM loop
if (iter == max_iter && param_change >= tol) {
warning("EM algorithm did not converge within max_iter iterations.
Parameter change was: ", param_change)
}
return(list(mu0 = mu0, mu1 = mu1, sigma2 = sigma2,
iterations = iter, converged=(param_change < tol),
history=param_hist[1:(iter+1),]))
}
# Define True Parameters
true_mu0 <- 2
true_mu1 <- 4
true_sigma2 <- 1
n_sim <- 1000
# Simulate Data
set.seed(12)
sim_data <- simulate_z_u(n_sim, true_mu0, true_mu1, true_sigma2)
z_obs <- sim_data$z
u_obs <- sim_data$u
# Set Initial Guesses
init_mu0 <- mean(z_obs[u_obs==0]) # Guess based on observed z when x is max
init_mu1 <- mean(z_obs[u_obs==1]) # Guess based on observed z when y is max
init_sigma2 <- var(z_obs) # Guess based on variance of observed z
# Run EM Algorithm
em_results <- em_algorithm(z = z_obs, u = u_obs,
mu0_init = init_mu0,
mu1_init = init_mu1,
sigma2_init = init_sigma2,
tol = 1e-7, max_iter = 1000)
# Print Initial Guesses
cat(paste("Initial Guesses:",
"\nmu0:", round(init_mu0, 4),
"\nmu1:", round(init_mu1, 4),
"\nsigma^2:", round(init_sigma2, 4)))
# Compare Estimated vs True Parameters
cat(paste("--- Results ---", "\nConverged:", em_results$converged, "\nIterations:", em_results$iterations))
cat(paste("True Parameters:", "\nmu0:", true_mu0, "\nmu1:", true_mu1, "\nsigma^2:", true_sigma2))
if (em_results$converged || em_results$iterations == 500) { # Show results even if max_iter hit
cat(paste("Estimated Parameters:",
"mu0:", round(em_results$mu0, 4),
"\nmu1:", round(em_results$mu1, 4),
"\nsigma^2:", round(em_results$sigma2, 4)))
} else {
cat("Estimation failed.")
}
# Convert the history matrix to a data frame
history_df <- as.data.frame(em_results$history)
colnames(history_df) <- c("mu0", "mu1", "sigma^2") # Assign names
# Add an iteration column (starting from 0 for initial values)
history_df$Iteration <- 0:(nrow(history_df) - 1)
# Reshape data to long format for ggplot
history_long <- tidyr::pivot_longer(history_df,
cols = c("mu0", "mu1", "sigma^2"),
names_to = "Parameter",
values_to = "Value")
# Create the plot
plot_history <- ggplot(history_long, aes(x = Iteration, y = Value, color = Parameter)) +
geom_line(linewidth = 0.8) +
# horizontal line for true values
geom_hline(yintercept = true_mu0, linetype = "dashed", color = "#e41a1c") +
geom_hline(yintercept = true_mu1, linetype = "dashed", color = "#377eb8") +
geom_hline(yintercept = true_sigma2, linetype = "dashed", color = "#4daf4a") +
labs(title = "EM Algorithm Parameter Convergence",
x = "Iteration",
y = "Parameter Value",
color = "Parameter") +
theme_bw() + # Or theme_bw() or your preferred theme
scale_color_brewer(palette = "Set1") # Use a nice color palette
# Print the plot
print(plot_history)
#save the plot
ggsave("em_convergence_plot.png", plot = plot_history, width = 6, height = 4)
# Plot data
# Create a data frame for plotting
observed_df <- data.frame(
z = sim_data$z,
u = factor(sim_data$u, labels = c("z = x (x >= y)", "z = y (y > x)")) # Make u a factor with descriptive labels
)
# Create the density plot
plot_observed <- ggplot(observed_df, aes(x = z, fill = u, color = u)) +
geom_density(alpha = 0.6, linewidth = 0.8) + # Use alpha for transparency
labs(title = "Distribution of Observed Maximum (z)",
x = "Observed z = max(x, y)",
y = "Density",
fill = "Condition",  # Legend title for fill
color = "Condition") + # Legend title for color
theme_minimal() +
scale_fill_brewer(palette = "Dark2") + # Nice palette for fill
scale_color_brewer(palette = "Dark2")  # Matching palette for color
x_df <- data.frame(x = sim_data$x)
y_df <- data.frame(y = sim_data$y)
# Create the histogram for x
plot_x_hist <- ggplot(x_df, aes(x = x)) +
geom_histogram(aes(y = after_stat(density)), bins = 30, fill = "lightblue", color = "black", alpha = 0.7) +
stat_function(fun = dnorm, args = list(mean = true_mu0, sd = sqrt(true_sigma2)), color = "black", linewidth = 0.7) +
labs(title = "Histogram of X",
x = "X Values",
y = "Density") +
theme_minimal()
# Create the histogram for y
plot_y_hist <- ggplot(y_df, aes(x = y)) +
geom_histogram(aes(y = after_stat(density)), bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
stat_function(fun = dnorm, args = list(mean = true_mu1, sd = sqrt(true_sigma2)), color = "black", linewidth = 0.7) +
labs(title = "Histogram of Y",
x = "Y Values",
y = "Density") +
theme_minimal()
# Combine the two plots
combined_plot <- plot_observed + plot_x_hist + plot_y_hist +
plot_layout(ncol = 3)
print(combined_plot)
# Save the combined plot
ggsave("combined_plot.png", plot = combined_plot, width = 12, height = 6)
# EM Algorithm Function
em_gametes <- function(counts_obs, n_AaBb, n_total, tol=1e-8, max_iter=1000) {
# Initialize probabilities
p_AB <- 0.25
p_Ab <- 0.25
p_aB <- 0.25
p_ab <- 0.25
# Get observed counts into named variables
n1 <- counts_obs[1]; n2 <- counts_obs[2]; n3 <- counts_obs[3]
n5 <- counts_obs[5]; n7 <- counts_obs[7]; n8 <- counts_obs[8]
n9 <- counts_obs[9]; n10 <- counts_obs[10]
iter_history <- list() # Store history
delta <- Inf # Initialize difference
for (iter in 1:max_iter) {
p_old <- c(p_AB, p_Ab, p_aB, p_ab)
iter_history[[iter]] <- p_old # Store params before update
# --- E-step ---
term1 = p_AB * p_ab
term2 = p_Ab * p_aB
denom = term1 + term2
N_AB_ab_t <- n_AaBb * term1 / denom
N_Ab_aB_t <- n_AaBb * term2 / denom
# --- M-step ---
N_AB_t <- 2*n1 + n2 + n3 + N_AB_ab_t
N_Ab_t <- n2 + 2*n5 + N_Ab_aB_t + n7
N_aB_t <- n3 + N_Ab_aB_t + 2*n8 + n9
N_ab_t <- N_AB_ab_t + n7 + n9 + 2*n10
p_AB_new <- N_AB_t / (2 * n_total)
p_Ab_new <- N_Ab_t / (2 * n_total)
p_aB_new <- N_aB_t / (2 * n_total)
p_ab_new <- N_ab_t / (2 * n_total)
p_sum <- p_AB_new + p_Ab_new + p_aB_new + p_ab_new
p_AB <- p_AB_new / p_sum
p_Ab <- p_Ab_new / p_sum
p_aB <- p_aB_new / p_sum
p_ab <- p_ab_new / p_sum
# --- Check convergence ---
p_new <- c(p_AB, p_Ab, p_aB, p_ab)
delta <- sqrt(sum((p_new - p_old)^2))
if (delta < tol) {
iter_history[[iter+1]] <- p_new
break
}
} # End loop
if (iter == max_iter && delta >= tol) {
warning("EM algorithm did not converge within max_iter iterations.
Last change: ", delta)
}
# --- Calculate D_AB ---
p_A <- p_AB + p_Ab
p_B <- p_AB + p_aB
D_AB <- p_AB - p_A * p_B
return(list(p_gamete = c(AB=p_AB, Ab=p_Ab, aB=p_aB, ab=p_ab),
D_AB = D_AB,
iterations = iter,
converged = (delta < tol),
history = do.call(rbind, iter_history)))
}
counts_obs <- c(17,22,86,NA,5,NA,38,58,124,51)
n_AaBb <- 99 # n_AB/ab + n_Ab/aB
# Total sample size
n_total <- sum(counts_obs, na.rm = TRUE) + n_AaBb
# --- Run the EM algorithm ---
em_results <- em_gametes(counts_obs, n_AaBb, n_total, tol=1e-8, max_iter=1000)
# --- cat the results ---
cat(paste("--- EM Algorithm Results ---", "\nConverged:", em_results$converged, "\nIterations:", em_results$iterations))
cat(paste("Estimated Gamete Frequencies (p_AB, p_Ab, p_aB, p_ab):\n",
round(em_results$p_gamete[1], 5),
round(em_results$p_gamete[2], 5),
round(em_results$p_gamete[3], 5),
round(em_results$p_gamete[4], 5)))
cat(paste("Estimated Linkage Disequilibrium (D_AB):\n", round(em_results$D_AB, 5)))
# Extract the history matrix (p_AB, p_Ab, p_aB, p_ab)
history_p <- as.data.frame(em_results$history)
colnames(history_p) <- c("p_AB", "p_Ab", "p_aB", "p_ab")
# Calculate D_AB for each iteration in the history
D_AB_history <- numeric(nrow(history_p))
for (i in 1:nrow(history_p)) {
p_A_hist <- history_p$p_AB[i] + history_p$p_Ab[i]
p_B_hist <- history_p$p_AB[i] + history_p$p_aB[i]
D_AB_history[i] <- history_p$p_AB[i] - p_A_hist * p_B_hist
}
# Combine probabilities and D_AB history
history_df <- history_p
history_df$D_AB <- D_AB_history
# Add an iteration column (starting from 0 for initial values)
# The loop stores p_old in iter_history[[iter]], and the final value in iter+1
# So nrow is iter+1, representing iterations 0 to iter.
history_df$Iteration <- 0:(nrow(history_df) - 1)
# Reshape data to long format for ggplot
history_long <- tidyr::pivot_longer(history_df,
cols = c("p_AB", "p_Ab", "p_aB", "p_ab", "D_AB"),
names_to = "Parameter",
values_to = "Value")
# Ensure Parameter is treated as a factor for consistent plotting order/colors
history_long$Parameter <- factor(history_long$Parameter, levels = c("p_AB", "p_Ab", "p_aB", "p_ab", "D_AB"))
# Create the plot
plot_haplo_history <- ggplot(history_long, aes(x = Iteration, y = Value, color = Parameter)) +
geom_line(linewidth = 0.8) +
labs(title = "EM Algorithm Parameter Convergence",
x = "Iteration",
y = "Parameter Value",
color = "Parameter") +
theme_minimal() +
scale_color_brewer(palette = "Set1") # Use a nice color palette
# Print the plot
print(plot_haplo_history)
# Select Build, Build and reload to build and lode into the R-session.
mylm <- function(formula, data = list(), contrasts = NULL, ...){
# Extract model matrix & responses
mf <- model.frame(formula = formula, data = data)
X  <- model.matrix(attr(mf, "terms"), data = mf, contrasts.arg = contrasts)
y  <- model.response(mf)
terms <- attr(mf, "terms")
# Add code here to calculate coefficients, residuals, fitted values, etc...
qx <- qr(X)
## compute (x’x)^(-1) x’y
coef <- solve.qr(qx, y)
df <- nrow(X)-ncol(X)
sigma2 <- sum((y -X%*%coef)^2)/df
## compute sigma^2 * (x’x)^-1
vcov <- sigma2 * chol2inv(qx$qr)
se <- sqrt(diag(vcov))
tval <- coef / se
pval <- 2 * (1 - pnorm(abs(tval)))
est <- list(terms = terms,model = mf, coefficients = coef, vcov = vcov,
se = se, tval = tval, pval = pval)
# and store the results in the list est
# Store call and formula used
est$call <- match.call()
est$formula <- formula
# Set class name. This is very important!
class(est) <- 'mylm'
# Return the object with all results
return(est)
}
print.mylm <- function(object, ...){
# Code here is used when print(object) is used on objects of class "mylm"
# Useful functions include cat, print.default and format
cat('Info about object\n')
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
#install.packages("car")
library(car)
data(SLID, package = "carData")
SLID <- SLID[complete.cases(SLID), ]
library(mylm)
library(mylm)
# Select Build, Build and reload to build and lode into the R-session.
mylm <- function(formula, data = list(), contrasts = NULL, ...){
# Extract model matrix & responses
mf <- model.frame(formula = formula, data = data)
X  <- model.matrix(attr(mf, "terms"), data = mf, contrasts.arg = contrasts)
y  <- model.response(mf)
terms <- attr(mf, "terms")
# Add code here to calculate coefficients, residuals, fitted values, etc...
qx <- qr(X)
## compute (x’x)^(-1) x’y
coef <- solve.qr(qx, y)
df <- nrow(X)-ncol(X)
sigma2 <- sum((y -X%*%coef)^2)/df
## compute sigma^2 * (x’x)^-1
vcov <- sigma2 * chol2inv(qx$qr)
se <- sqrt(diag(vcov))
tval <- coef / se
pval <- 2 * (1 - pnorm(abs(tval)))
est <- list(terms = terms,model = mf, coefficients = coef, vcov = vcov,
se = se, tval = tval, pval = pval)
# and store the results in the list est
# Store call and formula used
est$call <- match.call()
est$formula <- formula
# Set class name. This is very important!
class(est) <- 'mylm'
# Return the object with all results
return(est)
}
print.mylm <- function(object, ...){
setwd("C:/Users/Simen/OneDrive - NTNU/FYSMAT/INDMAT/25H/GLM/GLM-kaoz/src/mylm")
setwd("C:/Users/Simen/OneDrive - NTNU/FYSMAT/INDMAT/25H/Prosjekt/Project_thesis/src")
cd ..
setwd("C:/Users/Simen/OneDrive - NTNU/FYSMAT/INDMAT/25H/Prosjekt/Project_thesis")
# ----- CONFIG -----
phenotype <- "thr_tarsus"  # set to "body_mass", "thr_tarsus", "thr_wing", etc.
infile <- "Data/AdultMorphology_20240201_fix.csv"
out_dir <- "Data/gnn"
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
n_individuals <- NULL
# ----- LIBS -----
suppressPackageStartupMessages({
library(data.table)
library(dplyr)
library(lme4)
})
# ----- LOAD + PREP -----
# The file uses semicolons in your header example; fread auto-detects but we'll be explicit.
dd <- fread(infile, sep = ";", data.table = FALSE)
# sanity check
req <- c("ringnr","adult_sex","year","month","day","locality","hatch_year","max_year",
"first_locality","last_locality", "body_mass","thr_bill_depth","thr_bill_length",
"thr_tarsus","thr_wing")
miss <- setdiff(req, names(dd))
if (length(miss)) stop("Missing columns: ", paste(miss, collapse=", "))
# keep only rows with non-missing phenotype
stopifnot(phenotype %in% colnames(dd))
dd <- dd[!is.na(dd[[phenotype]]), , drop = FALSE] %>%
mutate(
ringnr      = as.character(ringnr),
sex         = factor(ifelse(adult_sex == 1, "m",
ifelse(adult_sex == 2, "f", NA))),
month       = factor(as.integer(month)),
locality    = factor(locality),
hatch_year  = as.integer(as.character(hatch_year)),
max_year    = as.integer(as.character(max_year)),
age         = max_year - hatch_year
) %>%
filter(!is.na(sex), !is.na(month), !is.na(age),
!is.na(locality), !is.na(hatch_year))
message(sprintf("N individuals: %d; N observations: %d; phenotype: %s",
dplyr::n_distinct(dd$ringnr), nrow(dd), phenotype))
# ----- LMM (two-step): fixed + random -----
# Fixed: sex + month + age
# Random: (1|ringnr) + (1|locality) + (1|hatch_year)
form <- as.formula(paste0(phenotype, " ~ sex + month + age + (1|ringnr) + (1|locality) + (1|hatch_year)"))
# Optimizer choices: Nelder_Mead is often robust for these models
fit <- lmer(form, data = dd, control = lmerControl(optimizer = "Nelder_Mead"))
# quick convergence check
if (!is.null(warnings())) {
message("lmer emitted warnings (often harmless). Inspect if needed.")
}
# ----- EXTRACT ADJUSTED PHENOTYPE (BLUP for ringnr) -----
re_list <- ranef(fit, condVar = FALSE)
if (!"ringnr" %in% names(re_list)) stop("No random effect for ringnr found.")
re_id <- as.data.frame(re_list$ringnr)
colnames(re_id) <- "(Intercept)"
re_id$ringnr <- rownames(re_list$ringnr)
adj <- re_id %>%
transmute(ringnr = as.character(ringnr),
y_adjusted = `(Intercept)`)
# Also compute mean raw phenotype per individual and obs counts (useful for QA / later)
ind_stats <- dd %>%
group_by(ringnr) %>%
summarise(n_obs = dplyr::n(),
y_mean = mean(.data[[phenotype]], na.rm = TRUE),
.groups = "drop")
adj_phen <- adj %>% left_join(ind_stats, by = "ringnr")
# ----- (Optional) residuals at observation-level -----
res_df <- data.frame(
ringnr = dd$ringnr,
y_obs  = dd[[phenotype]],
resid  = resid(fit)
)
# ----- SAVE -----
adj_out   <- file.path(out_dir, paste0("adjusted_", phenotype, ".csv"))
resid_out <- file.path(out_dir, paste0("residuals_", phenotype, "_obs.csv"))
write.csv(adj_phen, adj_out, row.names = FALSE)
write.csv(res_df,  resid_out, row.names = FALSE)
message("Saved: ", adj_out)
message("Saved: ", resid_out)
# ----- PRINT A TINY SUMMARY -----
message("Adjusted phenotype summary (first 6):")
print(head(adj_phen, 6))
